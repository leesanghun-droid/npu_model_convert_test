/****************************************************************************
*   Generated by ACUITY 5.21.1_0702
*   Match ovxlib 1.1.30
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_genderh5.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        if( NULL == _node ) {\
            goto error;\
        }\
        _node->uid = (uint32_t)_uid;\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(uint32_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR_FROM_HANDLE(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (43)
#define NET_NORM_TENSOR_NUM     (3)
#define NET_CONST_TENSOR_NUM    (52)
#define NET_VIRTUAL_TENSOR_NUM  (43)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    int32_t ret;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = fseek(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    ret = fread(data, 1, sz, fp);
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateGenderh5
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx,
    const vsi_nn_preprocess_map_element_t * pre_process_map,
    uint32_t pre_process_map_count,
    const vsi_nn_postprocess_map_element_t * post_process_map,
    uint32_t post_process_map_count
    )
{
    uint32_t                _infinity = VSI_NN_FLOAT32_INF;
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;
    uint32_t                i = 0;
    char *                  use_img_process_s;
    int32_t                 enable_pre_post_process = 0;
    vsi_bool                sort = FALSE;

    uint32_t   perm_1[] = { 1, 2, 0, 3 };
    uint32_t   perm_2[] = { 2, 0, 1, 3 };
    uint32_t   shape_1[] = { -1, 1 };




    (void)(_infinity);
    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;
    memset( &attr, 0, sizeof( attr ) );

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
    }
    else
    {
        ctx = in_ctx;
    }

    use_img_process_s = getenv( "VSI_USE_IMAGE_PROCESS" );
    if( use_img_process_s )
    {
        enable_pre_post_process = atoi(use_img_process_s);
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphVersion( graph, VNN_VERSION_MAJOR, VNN_VERSION_MINOR, VNN_VERSION_PATCH );
    vsi_nn_SetGraphInputs( graph, NULL, 1 );
    vsi_nn_SetGraphOutputs( graph, NULL, 2 );

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/

    /*-----------------------------------------
      lid       - separable_conv2d_53_acuity_mark_perm_7
      var       - node[0]
      name      - separable_conv2d_53_acuity_mark_perm
      operation - permute
      input     - [3, 200, 200, 1]
      output    - [200, 200, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_PERMUTE, 1, 1, 7);
    node[0]->nn_param.permute.perm = perm_1;
    node[0]->nn_param.permute.dim_num = 4;

    /*-----------------------------------------
      lid       - separable_conv2d_53
      var       - node[1]
      name      - separable_conv2d
      operation - depthwise_convolution
      input     - [200, 200, 3, 1]
      filter    - [3, 3, 3, 1]
      output    - [198, 198, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_CONV2D, 3, 1, 53);
    node[1]->nn_param.conv2d.ksize[0] = 3;
    node[1]->nn_param.conv2d.ksize[1] = 3;
    node[1]->nn_param.conv2d.weights = 3;
    node[1]->nn_param.conv2d.stride[0] = 1;
    node[1]->nn_param.conv2d.stride[1] = 1;
    node[1]->nn_param.conv2d.pad[0] = 0;
    node[1]->nn_param.conv2d.pad[1] = 0;
    node[1]->nn_param.conv2d.pad[2] = 0;
    node[1]->nn_param.conv2d.pad[3] = 0;
    node[1]->nn_param.conv2d.dilation[0] = 1;
    node[1]->nn_param.conv2d.dilation[1] = 1;
    node[1]->nn_param.conv2d.multiplier = 1;
    node[1]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[1]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[1]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_54
      var       - node[2]
      name      - separable_conv2d
      operation - convolution
      input     - [198, 198, 3, 1]
      filter    - [1, 1, 3, 16]
      output    - [198, 198, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_CONV2D, 3, 1, 54);
    node[2]->nn_param.conv2d.ksize[0] = 1;
    node[2]->nn_param.conv2d.ksize[1] = 1;
    node[2]->nn_param.conv2d.weights = 16;
    node[2]->nn_param.conv2d.stride[0] = 1;
    node[2]->nn_param.conv2d.stride[1] = 1;
    node[2]->nn_param.conv2d.pad[0] = 0;
    node[2]->nn_param.conv2d.pad[1] = 0;
    node[2]->nn_param.conv2d.pad[2] = 0;
    node[2]->nn_param.conv2d.pad[3] = 0;
    node[2]->nn_param.conv2d.group = 1;
    node[2]->nn_param.conv2d.dilation[0] = 1;
    node[2]->nn_param.conv2d.dilation[1] = 1;
    node[2]->nn_param.conv2d.multiplier = 0;
    node[2]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[2]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[2]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_51
      var       - node[3]
      name      - p_re_lu
      operation - prelu
      input     - [198, 198, 16, 1]
      output    - [198, 198, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_PRELU, 2, 1, 51);

    /*-----------------------------------------
      lid       - max_pooling2d_50
      var       - node[4]
      name      - max_pooling2d
      operation - pooling
      input     - [198, 198, 16, 1]
      output    - [99, 99, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_POOL, 1, 1, 50);
    node[4]->nn_param.pool.ksize[0] = 2;
    node[4]->nn_param.pool.ksize[1] = 2;
    node[4]->nn_param.pool.stride[0] = 2;
    node[4]->nn_param.pool.stride[1] = 2;
    node[4]->nn_param.pool.pad[0] = 0;
    node[4]->nn_param.pool.pad[1] = 0;
    node[4]->nn_param.pool.pad[2] = 0;
    node[4]->nn_param.pool.pad[3] = 0;
    node[4]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[4]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[4]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_1_48
      var       - node[5]
      name      - separable_conv2d_1
      operation - depthwise_convolution
      input     - [99, 99, 16, 1]
      filter    - [3, 3, 16, 1]
      output    - [97, 97, 16, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_CONV2D, 3, 1, 48);
    node[5]->nn_param.conv2d.ksize[0] = 3;
    node[5]->nn_param.conv2d.ksize[1] = 3;
    node[5]->nn_param.conv2d.weights = 16;
    node[5]->nn_param.conv2d.stride[0] = 1;
    node[5]->nn_param.conv2d.stride[1] = 1;
    node[5]->nn_param.conv2d.pad[0] = 0;
    node[5]->nn_param.conv2d.pad[1] = 0;
    node[5]->nn_param.conv2d.pad[2] = 0;
    node[5]->nn_param.conv2d.pad[3] = 0;
    node[5]->nn_param.conv2d.dilation[0] = 1;
    node[5]->nn_param.conv2d.dilation[1] = 1;
    node[5]->nn_param.conv2d.multiplier = 1;
    node[5]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[5]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[5]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_1_49
      var       - node[6]
      name      - separable_conv2d_1
      operation - convolution
      input     - [97, 97, 16, 1]
      filter    - [1, 1, 16, 32]
      output    - [97, 97, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_CONV2D, 3, 1, 49);
    node[6]->nn_param.conv2d.ksize[0] = 1;
    node[6]->nn_param.conv2d.ksize[1] = 1;
    node[6]->nn_param.conv2d.weights = 32;
    node[6]->nn_param.conv2d.stride[0] = 1;
    node[6]->nn_param.conv2d.stride[1] = 1;
    node[6]->nn_param.conv2d.pad[0] = 0;
    node[6]->nn_param.conv2d.pad[1] = 0;
    node[6]->nn_param.conv2d.pad[2] = 0;
    node[6]->nn_param.conv2d.pad[3] = 0;
    node[6]->nn_param.conv2d.group = 1;
    node[6]->nn_param.conv2d.dilation[0] = 1;
    node[6]->nn_param.conv2d.dilation[1] = 1;
    node[6]->nn_param.conv2d.multiplier = 0;
    node[6]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[6]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[6]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_1_46
      var       - node[7]
      name      - p_re_lu_1
      operation - prelu
      input     - [97, 97, 32, 1]
      output    - [97, 97, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_PRELU, 2, 1, 46);

    /*-----------------------------------------
      lid       - max_pooling2d_1_45
      var       - node[8]
      name      - max_pooling2d_1
      operation - pooling
      input     - [97, 97, 32, 1]
      output    - [48, 48, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_POOL, 1, 1, 45);
    node[8]->nn_param.pool.ksize[0] = 2;
    node[8]->nn_param.pool.ksize[1] = 2;
    node[8]->nn_param.pool.stride[0] = 2;
    node[8]->nn_param.pool.stride[1] = 2;
    node[8]->nn_param.pool.pad[0] = 0;
    node[8]->nn_param.pool.pad[1] = 0;
    node[8]->nn_param.pool.pad[2] = 0;
    node[8]->nn_param.pool.pad[3] = 0;
    node[8]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[8]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[8]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_2_43
      var       - node[9]
      name      - separable_conv2d_2
      operation - depthwise_convolution
      input     - [48, 48, 32, 1]
      filter    - [3, 3, 32, 1]
      output    - [46, 46, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_CONV2D, 3, 1, 43);
    node[9]->nn_param.conv2d.ksize[0] = 3;
    node[9]->nn_param.conv2d.ksize[1] = 3;
    node[9]->nn_param.conv2d.weights = 32;
    node[9]->nn_param.conv2d.stride[0] = 1;
    node[9]->nn_param.conv2d.stride[1] = 1;
    node[9]->nn_param.conv2d.pad[0] = 0;
    node[9]->nn_param.conv2d.pad[1] = 0;
    node[9]->nn_param.conv2d.pad[2] = 0;
    node[9]->nn_param.conv2d.pad[3] = 0;
    node[9]->nn_param.conv2d.dilation[0] = 1;
    node[9]->nn_param.conv2d.dilation[1] = 1;
    node[9]->nn_param.conv2d.multiplier = 1;
    node[9]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[9]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[9]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_2_44
      var       - node[10]
      name      - separable_conv2d_2
      operation - convolution
      input     - [46, 46, 32, 1]
      filter    - [1, 1, 32, 64]
      output    - [46, 46, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_CONV2D, 3, 1, 44);
    node[10]->nn_param.conv2d.ksize[0] = 1;
    node[10]->nn_param.conv2d.ksize[1] = 1;
    node[10]->nn_param.conv2d.weights = 64;
    node[10]->nn_param.conv2d.stride[0] = 1;
    node[10]->nn_param.conv2d.stride[1] = 1;
    node[10]->nn_param.conv2d.pad[0] = 0;
    node[10]->nn_param.conv2d.pad[1] = 0;
    node[10]->nn_param.conv2d.pad[2] = 0;
    node[10]->nn_param.conv2d.pad[3] = 0;
    node[10]->nn_param.conv2d.group = 1;
    node[10]->nn_param.conv2d.dilation[0] = 1;
    node[10]->nn_param.conv2d.dilation[1] = 1;
    node[10]->nn_param.conv2d.multiplier = 0;
    node[10]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[10]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[10]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_2_41
      var       - node[11]
      name      - p_re_lu_2
      operation - prelu
      input     - [46, 46, 64, 1]
      output    - [46, 46, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_PRELU, 2, 1, 41);

    /*-----------------------------------------
      lid       - max_pooling2d_2_40
      var       - node[12]
      name      - max_pooling2d_2
      operation - pooling
      input     - [46, 46, 64, 1]
      output    - [23, 23, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_POOL, 1, 1, 40);
    node[12]->nn_param.pool.ksize[0] = 2;
    node[12]->nn_param.pool.ksize[1] = 2;
    node[12]->nn_param.pool.stride[0] = 2;
    node[12]->nn_param.pool.stride[1] = 2;
    node[12]->nn_param.pool.pad[0] = 0;
    node[12]->nn_param.pool.pad[1] = 0;
    node[12]->nn_param.pool.pad[2] = 0;
    node[12]->nn_param.pool.pad[3] = 0;
    node[12]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[12]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[12]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_3_38
      var       - node[13]
      name      - separable_conv2d_3
      operation - depthwise_convolution
      input     - [23, 23, 64, 1]
      filter    - [3, 3, 64, 1]
      output    - [21, 21, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_CONV2D, 3, 1, 38);
    node[13]->nn_param.conv2d.ksize[0] = 3;
    node[13]->nn_param.conv2d.ksize[1] = 3;
    node[13]->nn_param.conv2d.weights = 64;
    node[13]->nn_param.conv2d.stride[0] = 1;
    node[13]->nn_param.conv2d.stride[1] = 1;
    node[13]->nn_param.conv2d.pad[0] = 0;
    node[13]->nn_param.conv2d.pad[1] = 0;
    node[13]->nn_param.conv2d.pad[2] = 0;
    node[13]->nn_param.conv2d.pad[3] = 0;
    node[13]->nn_param.conv2d.dilation[0] = 1;
    node[13]->nn_param.conv2d.dilation[1] = 1;
    node[13]->nn_param.conv2d.multiplier = 1;
    node[13]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[13]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[13]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_3_39
      var       - node[14]
      name      - separable_conv2d_3
      operation - convolution
      input     - [21, 21, 64, 1]
      filter    - [1, 1, 64, 128]
      output    - [21, 21, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_CONV2D, 3, 1, 39);
    node[14]->nn_param.conv2d.ksize[0] = 1;
    node[14]->nn_param.conv2d.ksize[1] = 1;
    node[14]->nn_param.conv2d.weights = 128;
    node[14]->nn_param.conv2d.stride[0] = 1;
    node[14]->nn_param.conv2d.stride[1] = 1;
    node[14]->nn_param.conv2d.pad[0] = 0;
    node[14]->nn_param.conv2d.pad[1] = 0;
    node[14]->nn_param.conv2d.pad[2] = 0;
    node[14]->nn_param.conv2d.pad[3] = 0;
    node[14]->nn_param.conv2d.group = 1;
    node[14]->nn_param.conv2d.dilation[0] = 1;
    node[14]->nn_param.conv2d.dilation[1] = 1;
    node[14]->nn_param.conv2d.multiplier = 0;
    node[14]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[14]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[14]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_3_36
      var       - node[15]
      name      - p_re_lu_3
      operation - prelu
      input     - [21, 21, 128, 1]
      output    - [21, 21, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_PRELU, 2, 1, 36);

    /*-----------------------------------------
      lid       - max_pooling2d_3_35
      var       - node[16]
      name      - max_pooling2d_3
      operation - pooling
      input     - [21, 21, 128, 1]
      output    - [10, 10, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_POOL, 1, 1, 35);
    node[16]->nn_param.pool.ksize[0] = 2;
    node[16]->nn_param.pool.ksize[1] = 2;
    node[16]->nn_param.pool.stride[0] = 2;
    node[16]->nn_param.pool.stride[1] = 2;
    node[16]->nn_param.pool.pad[0] = 0;
    node[16]->nn_param.pool.pad[1] = 0;
    node[16]->nn_param.pool.pad[2] = 0;
    node[16]->nn_param.pool.pad[3] = 0;
    node[16]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[16]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[16]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_4_33
      var       - node[17]
      name      - separable_conv2d_4
      operation - depthwise_convolution
      input     - [10, 10, 128, 1]
      filter    - [3, 3, 128, 1]
      output    - [8, 8, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_CONV2D, 3, 1, 33);
    node[17]->nn_param.conv2d.ksize[0] = 3;
    node[17]->nn_param.conv2d.ksize[1] = 3;
    node[17]->nn_param.conv2d.weights = 128;
    node[17]->nn_param.conv2d.stride[0] = 1;
    node[17]->nn_param.conv2d.stride[1] = 1;
    node[17]->nn_param.conv2d.pad[0] = 0;
    node[17]->nn_param.conv2d.pad[1] = 0;
    node[17]->nn_param.conv2d.pad[2] = 0;
    node[17]->nn_param.conv2d.pad[3] = 0;
    node[17]->nn_param.conv2d.dilation[0] = 1;
    node[17]->nn_param.conv2d.dilation[1] = 1;
    node[17]->nn_param.conv2d.multiplier = 1;
    node[17]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[17]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[17]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_4_34
      var       - node[18]
      name      - separable_conv2d_4
      operation - convolution
      input     - [8, 8, 128, 1]
      filter    - [1, 1, 128, 256]
      output    - [8, 8, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_CONV2D, 3, 1, 34);
    node[18]->nn_param.conv2d.ksize[0] = 1;
    node[18]->nn_param.conv2d.ksize[1] = 1;
    node[18]->nn_param.conv2d.weights = 256;
    node[18]->nn_param.conv2d.stride[0] = 1;
    node[18]->nn_param.conv2d.stride[1] = 1;
    node[18]->nn_param.conv2d.pad[0] = 0;
    node[18]->nn_param.conv2d.pad[1] = 0;
    node[18]->nn_param.conv2d.pad[2] = 0;
    node[18]->nn_param.conv2d.pad[3] = 0;
    node[18]->nn_param.conv2d.group = 1;
    node[18]->nn_param.conv2d.dilation[0] = 1;
    node[18]->nn_param.conv2d.dilation[1] = 1;
    node[18]->nn_param.conv2d.multiplier = 0;
    node[18]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[18]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[18]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_4_31
      var       - node[19]
      name      - p_re_lu_4
      operation - prelu
      input     - [8, 8, 256, 1]
      output    - [8, 8, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_PRELU, 2, 1, 31);

    /*-----------------------------------------
      lid       - max_pooling2d_4_30
      var       - node[20]
      name      - max_pooling2d_4
      operation - pooling
      input     - [8, 8, 256, 1]
      output    - [4, 4, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_POOL, 1, 1, 30);
    node[20]->nn_param.pool.ksize[0] = 2;
    node[20]->nn_param.pool.ksize[1] = 2;
    node[20]->nn_param.pool.stride[0] = 2;
    node[20]->nn_param.pool.stride[1] = 2;
    node[20]->nn_param.pool.pad[0] = 0;
    node[20]->nn_param.pool.pad[1] = 0;
    node[20]->nn_param.pool.pad[2] = 0;
    node[20]->nn_param.pool.pad[3] = 0;
    node[20]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[20]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[20]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_5_28
      var       - node[21]
      name      - separable_conv2d_5
      operation - depthwise_convolution
      input     - [4, 4, 256, 1]
      filter    - [3, 3, 256, 1]
      output    - [2, 2, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_CONV2D, 3, 1, 28);
    node[21]->nn_param.conv2d.ksize[0] = 3;
    node[21]->nn_param.conv2d.ksize[1] = 3;
    node[21]->nn_param.conv2d.weights = 256;
    node[21]->nn_param.conv2d.stride[0] = 1;
    node[21]->nn_param.conv2d.stride[1] = 1;
    node[21]->nn_param.conv2d.pad[0] = 0;
    node[21]->nn_param.conv2d.pad[1] = 0;
    node[21]->nn_param.conv2d.pad[2] = 0;
    node[21]->nn_param.conv2d.pad[3] = 0;
    node[21]->nn_param.conv2d.dilation[0] = 1;
    node[21]->nn_param.conv2d.dilation[1] = 1;
    node[21]->nn_param.conv2d.multiplier = 1;
    node[21]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[21]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[21]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - separable_conv2d_5_29
      var       - node[22]
      name      - separable_conv2d_5
      operation - convolution
      input     - [2, 2, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [2, 2, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_CONV2D, 3, 1, 29);
    node[22]->nn_param.conv2d.ksize[0] = 1;
    node[22]->nn_param.conv2d.ksize[1] = 1;
    node[22]->nn_param.conv2d.weights = 256;
    node[22]->nn_param.conv2d.stride[0] = 1;
    node[22]->nn_param.conv2d.stride[1] = 1;
    node[22]->nn_param.conv2d.pad[0] = 0;
    node[22]->nn_param.conv2d.pad[1] = 0;
    node[22]->nn_param.conv2d.pad[2] = 0;
    node[22]->nn_param.conv2d.pad[3] = 0;
    node[22]->nn_param.conv2d.group = 1;
    node[22]->nn_param.conv2d.dilation[0] = 1;
    node[22]->nn_param.conv2d.dilation[1] = 1;
    node[22]->nn_param.conv2d.multiplier = 0;
    node[22]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[22]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[22]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_5_26
      var       - node[23]
      name      - p_re_lu_5
      operation - prelu
      input     - [2, 2, 256, 1]
      output    - [2, 2, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_PRELU, 2, 1, 26);

    /*-----------------------------------------
      lid       - max_pooling2d_5_25
      var       - node[24]
      name      - max_pooling2d_5
      operation - pooling
      input     - [2, 2, 256, 1]
      output    - [1, 1, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_POOL, 1, 1, 25);
    node[24]->nn_param.pool.ksize[0] = 2;
    node[24]->nn_param.pool.ksize[1] = 2;
    node[24]->nn_param.pool.stride[0] = 2;
    node[24]->nn_param.pool.stride[1] = 2;
    node[24]->nn_param.pool.pad[0] = 0;
    node[24]->nn_param.pool.pad[1] = 0;
    node[24]->nn_param.pool.pad[2] = 0;
    node[24]->nn_param.pool.pad[3] = 0;
    node[24]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[24]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[24]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - flatten_24_acuity_mark_perm_6
      var       - node[25]
      name      - flatten_24_acuity_mark_perm
      operation - permute
      input     - [1, 1, 256, 1]
      output    - [256, 1, 1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_PERMUTE, 1, 1, 6);
    node[25]->nn_param.permute.perm = perm_2;
    node[25]->nn_param.permute.dim_num = 4;

    /*-----------------------------------------
      lid       - flatten_24
      var       - node[26]
      name      - flatten
      operation - reshape
      input     - [256, 1, 1, 1]
      output    - [256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_RESHAPE, 1, 1, 24);
    node[26]->nn_param.reshape.size = shape_1;
    node[26]->nn_param.reshape.dim_num = 2;

    /*-----------------------------------------
      lid       - dense_3_22
      var       - node[27]
      name      - dense_3
      operation - fullconnect
      input     - [256, 1]
      filter    - [256, 256]
      output    - [256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_FCL, 3, 1, 22);
    node[27]->nn_param.fcl.weights = 256;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - dense_23
      var       - node[28]
      name      - dense
      operation - fullconnect
      input     - [256, 1]
      filter    - [256, 256]
      output    - [256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_FCL, 3, 1, 23);
    node[28]->nn_param.fcl.weights = 256;
    node[28]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[28]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[28]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_9_20
      var       - node[29]
      name      - p_re_lu_9
      operation - prelu
      input     - [256, 1]
      output    - [256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_PRELU, 2, 1, 20);

    /*-----------------------------------------
      lid       - p_re_lu_6_21
      var       - node[30]
      name      - p_re_lu_6
      operation - prelu
      input     - [256, 1]
      output    - [256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_PRELU, 2, 1, 21);

    /*-----------------------------------------
      lid       - dense_4_16
      var       - node[31]
      name      - dense_4
      operation - fullconnect
      input     - [256, 1]
      filter    - [256, 64]
      output    - [64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_FCL, 3, 1, 16);
    node[31]->nn_param.fcl.weights = 64;
    node[31]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[31]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[31]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - dense_1_17
      var       - node[32]
      name      - dense_1
      operation - fullconnect
      input     - [256, 1]
      filter    - [256, 64]
      output    - [64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_FCL, 3, 1, 17);
    node[32]->nn_param.fcl.weights = 64;
    node[32]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[32]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[32]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_10_14
      var       - node[33]
      name      - p_re_lu_10
      operation - prelu
      input     - [64, 1]
      output    - [64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[33], VSI_NN_OP_PRELU, 2, 1, 14);

    /*-----------------------------------------
      lid       - p_re_lu_7_15
      var       - node[34]
      name      - p_re_lu_7
      operation - prelu
      input     - [64, 1]
      output    - [64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[34], VSI_NN_OP_PRELU, 2, 1, 15);

    /*-----------------------------------------
      lid       - dense_5_10
      var       - node[35]
      name      - dense_5
      operation - fullconnect
      input     - [64, 1]
      filter    - [64, 32]
      output    - [32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[35], VSI_NN_OP_FCL, 3, 1, 10);
    node[35]->nn_param.fcl.weights = 32;
    node[35]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[35]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[35]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - dense_2_11
      var       - node[36]
      name      - dense_2
      operation - fullconnect
      input     - [64, 1]
      filter    - [64, 32]
      output    - [32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[36], VSI_NN_OP_FCL, 3, 1, 11);
    node[36]->nn_param.fcl.weights = 32;
    node[36]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[36]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[36]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - p_re_lu_11_8
      var       - node[37]
      name      - p_re_lu_11
      operation - prelu
      input     - [32, 1]
      output    - [32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[37], VSI_NN_OP_PRELU, 2, 1, 8);

    /*-----------------------------------------
      lid       - p_re_lu_8_9
      var       - node[38]
      name      - p_re_lu_8
      operation - prelu
      input     - [32, 1]
      output    - [32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[38], VSI_NN_OP_PRELU, 2, 1, 9);

    /*-----------------------------------------
      lid       - output_upper_bound_2
      var       - node[39]
      name      - output_upper_bound
      operation - fullconnect
      input     - [32, 1]
      filter    - [32, 1]
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[39], VSI_NN_OP_FCL, 3, 1, 2);
    node[39]->nn_param.fcl.weights = 1;
    node[39]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[39]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[39]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - output_lower_bound_4
      var       - node[40]
      name      - output_lower_bound
      operation - fullconnect
      input     - [32, 1]
      filter    - [32, 1]
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[40], VSI_NN_OP_FCL, 3, 1, 4);
    node[40]->nn_param.fcl.weights = 1;
    node[40]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[40]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_ZERO;
    node[40]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - output_upper_bound_relu_3
      var       - node[41]
      name      - output_upper_bound_relu
      operation - relu
      input     - [1, 1]
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[41], VSI_NN_OP_RELU, 1, 1, 3);

    /*-----------------------------------------
      lid       - output_lower_bound_relu_5
      var       - node[42]
      name      - output_lower_bound_relu
      operation - relu
      input     - [1, 1]
      output    - [1, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[42], VSI_NN_OP_RELU, 1, 1, 5);


/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @attach_output_lower_bound/Relu/out0_0:out0 */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.scale = 0.0032271239906549454;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_UINT8);

    /* @attach_output_upper_bound/Relu/out0_1:out0 */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.scale = 0.003031496424227953;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_UINT8);

    /* @input_image_55:out0 */
    attr.size[0] = 3;
    attr.size[1] = 200;
    attr.size[2] = 200;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00390625;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[2], attr, VSI_NN_TYPE_UINT8);



    /* @separable_conv2d_53:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003552116919308901;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_UINT8, 222308, 27);

    /* @separable_conv2d_53:bias */
    attr.size[0] = 3;
    attr.dim_num = 1;
    attr.dtype.scale = 1.3875456716050394e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_INT32, 222296, 12);

    /* @separable_conv2d_54:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 3;
    attr.size[3] = 16;
    attr.dim_num = 4;
    attr.dtype.scale = 0.11093895137310028;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_UINT8, 222399, 48);

    /* @separable_conv2d_54:bias */
    attr.size[0] = 16;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0005687720359698265;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_INT32, 222335, 64);

    /* @p_re_lu_51:a */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 16;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_FLOAT16, 171976, 32);

    /* @separable_conv2d_1_48:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 16;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0016918296460062265;
    attr.dtype.zero_point = 118;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_UINT8, 173800, 144);

    /* @separable_conv2d_1_48:bias */
    attr.size[0] = 16;
    attr.dim_num = 1;
    attr.dtype.scale = 5.050445616054016e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_INT32, 173736, 64);

    /* @separable_conv2d_1_49:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 16;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.03850072994828224;
    attr.dtype.zero_point = 117;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_UINT8, 174072, 512);

    /* @separable_conv2d_1_49:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0006369259303216357;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_INT32, 173944, 128);

    /* @p_re_lu_1_46:a */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_FLOAT16, 171016, 64);

    /* @separable_conv2d_2_43:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0015933903632685542;
    attr.dtype.zero_point = 111;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_UINT8, 174712, 288);

    /* @separable_conv2d_2_43:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 9.975407474885171e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_INT32, 174584, 128);

    /* @separable_conv2d_2_44:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.02084394544363022;
    attr.dtype.zero_point = 123;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_UINT8, 175256, 2048);

    /* @separable_conv2d_2_44:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0005894741775022694;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_INT32, 175000, 256);

    /* @p_re_lu_2_41:a */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_FLOAT16, 171080, 128);

    /* @separable_conv2d_3_38:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0011409560684114695;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_UINT8, 177560, 576);

    /* @separable_conv2d_3_38:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 5.201434487280259e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_INT32, 177304, 256);

    /* @separable_conv2d_3_39:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.02157405950129032;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_UINT8, 178648, 8192);

    /* @separable_conv2d_3_39:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00041520351644612485;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_INT32, 178136, 512);

    /* @p_re_lu_3_36:a */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_FLOAT16, 171208, 256);

    /* @separable_conv2d_4_33:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0010514764580875635;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_UINT8, 187352, 1152);

    /* @separable_conv2d_4_33:bias */
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 2.938400780046549e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_INT32, 186840, 512);

    /* @separable_conv2d_4_34:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.02539491467177868;
    attr.dtype.zero_point = 116;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_UINT8, 189528, 32768);

    /* @separable_conv2d_4_34:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00015574667804902406;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_INT32, 188504, 1024);

    /* @p_re_lu_4_31:a */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_FLOAT16, 171464, 512);

    /* @separable_conv2d_5_28:weight */
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.001351906917989254;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_UINT8, 223471, 2304);

    /* @separable_conv2d_5_28:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 2.9006906934646998e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_INT32, 222447, 1024);

    /* @separable_conv2d_5_29:weight */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.020847933366894722;
    attr.dtype.zero_point = 115;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_UINT8, 226799, 65536);

    /* @separable_conv2d_5_29:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014241116688753965;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_INT32, 225775, 1024);

    /* @p_re_lu_5_26:a */
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_FLOAT16, 172008, 512);

    /* @dense_3_22:weight */
    attr.size[0] = 256;
    attr.size[1] = 256;
    attr.dim_num = 2;
    attr.dtype.scale = 2.6862511731451377e-05;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_UINT8, 86400, 65536);

    /* @dense_3_22:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 1.0715116350077611e-06;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_INT32, 85376, 1024);

    /* @dense_23:weight */
    attr.size[0] = 256;
    attr.size[1] = 256;
    attr.dim_num = 2;
    attr.dtype.scale = 2.444487290631514e-05;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_UINT8, 17664, 65536);

    /* @dense_23:bias */
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 9.75075078505604e-07;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_INT32, 16640, 1024);

    /* @p_re_lu_9_20:a */
    attr.size[0] = 256;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_FLOAT16, 173224, 512);

    /* @p_re_lu_6_21:a */
    attr.size[0] = 256;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_FLOAT16, 172520, 512);

    /* @dense_4_16:weight */
    attr.size[0] = 256;
    attr.size[1] = 64;
    attr.dim_num = 2;
    attr.dtype.scale = 4.04633319703862e-05;
    attr.dtype.zero_point = 125;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_UINT8, 152192, 16384);

    /* @dense_4_16:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 4.555315013241755e-07;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_INT32, 151936, 256);

    /* @dense_1_17:weight */
    attr.size[0] = 256;
    attr.size[1] = 64;
    attr.dim_num = 2;
    attr.dtype.scale = 4.156899012741632e-05;
    attr.dtype.zero_point = 115;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_UINT8, 256, 16384);

    /* @dense_1_17:bias */
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 4.795728281661909e-07;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_INT32, 0, 256);

    /* @p_re_lu_10_14:a */
    attr.size[0] = 64;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_FLOAT16, 170824, 128);

    /* @p_re_lu_7_15:a */
    attr.size[0] = 64;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_FLOAT16, 173032, 128);

    /* @dense_5_10:weight */
    attr.size[0] = 64;
    attr.size[1] = 32;
    attr.dim_num = 2;
    attr.dtype.scale = 7.292061491170898e-05;
    attr.dtype.zero_point = 137;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_UINT8, 168704, 2048);

    /* @dense_5_10:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 1.5454800749008155e-07;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_INT32, 168576, 128);

    /* @dense_2_11:weight */
    attr.size[0] = 64;
    attr.size[1] = 32;
    attr.dim_num = 2;
    attr.dtype.scale = 5.974541272735223e-05;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_UINT8, 83328, 2048);

    /* @dense_2_11:bias */
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 1.1576741162443466e-07;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_INT32, 83200, 128);

    /* @p_re_lu_11_8:a */
    attr.size[0] = 32;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_FLOAT16, 170952, 64);

    /* @p_re_lu_8_9:a */
    attr.size[0] = 32;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_NONE;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_FLOAT16, 173160, 64);

    /* @output_upper_bound_2:weight */
    attr.size[0] = 32;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.scale = 0.0065869600512087345;
    attr.dtype.zero_point = 145;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_UINT8, 170792, 32);

    /* @output_upper_bound_2:bias */
    attr.size[0] = 1;
    attr.dim_num = 1;
    attr.dtype.scale = 2.1333502940467953e-06;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_INT32, 170788, 4);

    /* @output_lower_bound_4:weight */
    attr.size[0] = 32;
    attr.size[1] = 1;
    attr.dim_num = 2;
    attr.dtype.scale = 0.0056219156831502914;
    attr.dtype.zero_point = 143;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_UINT8, 170756, 32);

    /* @output_lower_bound_4:bias */
    attr.size[0] = 1;
    attr.dim_num = 1;
    attr.dtype.scale = 1.8312652785705845e-06;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_INT32, 170752, 4);



    /* @separable_conv2d_53_acuity_mark_perm_7:out0 */
    attr.dtype.scale = 0.00390625;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_53:out0 */
    attr.dtype.scale = 0.005126892123371363;
    attr.dtype.zero_point = 179;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_54:out0 */
    attr.dtype.scale = 0.05503992736339569;
    attr.dtype.zero_point = 136;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_51:out0 */
    attr.dtype.scale = 0.029851974919438362;
    attr.dtype.zero_point = 36;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @max_pooling2d_50:out0 */
    attr.dtype.scale = 0.029851974919438362;
    attr.dtype.zero_point = 36;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_1_48:out0 */
    attr.dtype.scale = 0.01654321700334549;
    attr.dtype.zero_point = 70;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_1_49:out0 */
    attr.dtype.scale = 0.10181029140949249;
    attr.dtype.zero_point = 112;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_1_46:out0 */
    attr.dtype.scale = 0.06260491907596588;
    attr.dtype.zero_point = 23;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @max_pooling2d_1_45:out0 */
    attr.dtype.scale = 0.06260491907596588;
    attr.dtype.zero_point = 23;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_2_43:out0 */
    attr.dtype.scale = 0.028280355036258698;
    attr.dtype.zero_point = 99;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_2_44:out0 */
    attr.dtype.scale = 0.0842326283454895;
    attr.dtype.zero_point = 132;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_2_41:out0 */
    attr.dtype.scale = 0.04558838531374931;
    attr.dtype.zero_point = 27;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @max_pooling2d_2_40:out0 */
    attr.dtype.scale = 0.04558838531374931;
    attr.dtype.zero_point = 27;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_3_38:out0 */
    attr.dtype.scale = 0.01924549788236618;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_3_39:out0 */
    attr.dtype.scale = 0.05419421195983887;
    attr.dtype.zero_point = 140;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_3_36:out0 */
    attr.dtype.scale = 0.027945473790168762;
    attr.dtype.zero_point = 31;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @max_pooling2d_3_35:out0 */
    attr.dtype.scale = 0.027945473790168762;
    attr.dtype.zero_point = 31;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_4_33:out0 */
    attr.dtype.scale = 0.0061329868622124195;
    attr.dtype.zero_point = 119;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_4_34:out0 */
    attr.dtype.scale = 0.04182528331875801;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_4_31:out0 */
    attr.dtype.scale = 0.021456290036439896;
    attr.dtype.zero_point = 19;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @max_pooling2d_4_30:out0 */
    attr.dtype.scale = 0.021456290036439896;
    attr.dtype.zero_point = 19;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_5_28:out0 */
    attr.dtype.scale = 0.006830948870629072;
    attr.dtype.zero_point = 145;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @separable_conv2d_5_29:out0 */
    attr.dtype.scale = 0.05639156326651573;
    attr.dtype.zero_point = 94;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_5_26:out0 */
    attr.dtype.scale = 0.039888735860586166;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @max_pooling2d_5_25:out0 */
    attr.dtype.scale = 0.039888735860586166;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @flatten_24_acuity_mark_perm_6:out0 */
    attr.dtype.scale = 0.039888735860586166;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @flatten_24:out0 */
    attr.dtype.scale = 0.039888735860586166;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @dense_3_22:out0 */
    attr.dtype.scale = 0.012507169507443905;
    attr.dtype.zero_point = 103;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @dense_23:out0 */
    attr.dtype.scale = 0.012638583779335022;
    attr.dtype.zero_point = 114;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_9_20:out0 */
    attr.dtype.scale = 0.011257884092628956;
    attr.dtype.zero_point = 86;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_6_21:out0 */
    attr.dtype.scale = 0.011536792851984501;
    attr.dtype.zero_point = 100;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @dense_4_16:out0 */
    attr.dtype.scale = 0.002303703222423792;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @dense_1_17:out0 */
    attr.dtype.scale = 0.002257338957861066;
    attr.dtype.zero_point = 111;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[32]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_10_14:out0 */
    attr.dtype.scale = 0.0021194007713347673;
    attr.dtype.zero_point = 112;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[33]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_7_15:out0 */
    attr.dtype.scale = 0.0019376786658540368;
    attr.dtype.zero_point = 87;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[34]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @dense_5_10:out0 */
    attr.dtype.scale = 0.0004552867030724883;
    attr.dtype.zero_point = 112;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[35]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @dense_2_11:out0 */
    attr.dtype.scale = 0.00045379591756500304;
    attr.dtype.zero_point = 113;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[36]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_11_8:out0 */
    attr.dtype.scale = 0.0003238747885916382;
    attr.dtype.zero_point = 53;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[37]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @p_re_lu_8_9:out0 */
    attr.dtype.scale = 0.0003257368807680905;
    attr.dtype.zero_point = 57;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[38]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @output_upper_bound_2:out0 */
    attr.dtype.scale = 0.003031496424227953;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[39]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @output_lower_bound_4:out0 */
    attr.dtype.scale = 0.0032271239906549454;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[40]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[0]->input.tensors[0] = norm_tensor[2];
    node[41]->output.tensors[0] = norm_tensor[1];
    node[42]->output.tensors[0] = norm_tensor[0];

    /* separable_conv2d_53_acuity_mark_perm_7 */

    /* separable_conv2d_53 */
    node[1]->input.tensors[0] = node[0]->output.tensors[0];
    node[1]->input.tensors[1] = const_tensor[0]; /* data_weight */
    node[1]->input.tensors[2] = const_tensor[1]; /* data_bias */

    /* separable_conv2d_54 */
    node[2]->input.tensors[0] = node[1]->output.tensors[0];
    node[2]->input.tensors[1] = const_tensor[2]; /* data_weight */
    node[2]->input.tensors[2] = const_tensor[3]; /* data_bias */

    /* p_re_lu_51 */
    node[3]->input.tensors[0] = node[2]->output.tensors[0];
    node[3]->input.tensors[1] = const_tensor[4]; /* data_a */

    /* max_pooling2d_50 */
    node[4]->input.tensors[0] = node[3]->output.tensors[0];

    /* separable_conv2d_1_48 */
    node[5]->input.tensors[0] = node[4]->output.tensors[0];
    node[5]->input.tensors[1] = const_tensor[5]; /* data_weight */
    node[5]->input.tensors[2] = const_tensor[6]; /* data_bias */

    /* separable_conv2d_1_49 */
    node[6]->input.tensors[0] = node[5]->output.tensors[0];
    node[6]->input.tensors[1] = const_tensor[7]; /* data_weight */
    node[6]->input.tensors[2] = const_tensor[8]; /* data_bias */

    /* p_re_lu_1_46 */
    node[7]->input.tensors[0] = node[6]->output.tensors[0];
    node[7]->input.tensors[1] = const_tensor[9]; /* data_a */

    /* max_pooling2d_1_45 */
    node[8]->input.tensors[0] = node[7]->output.tensors[0];

    /* separable_conv2d_2_43 */
    node[9]->input.tensors[0] = node[8]->output.tensors[0];
    node[9]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[9]->input.tensors[2] = const_tensor[11]; /* data_bias */

    /* separable_conv2d_2_44 */
    node[10]->input.tensors[0] = node[9]->output.tensors[0];
    node[10]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[10]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* p_re_lu_2_41 */
    node[11]->input.tensors[0] = node[10]->output.tensors[0];
    node[11]->input.tensors[1] = const_tensor[14]; /* data_a */

    /* max_pooling2d_2_40 */
    node[12]->input.tensors[0] = node[11]->output.tensors[0];

    /* separable_conv2d_3_38 */
    node[13]->input.tensors[0] = node[12]->output.tensors[0];
    node[13]->input.tensors[1] = const_tensor[15]; /* data_weight */
    node[13]->input.tensors[2] = const_tensor[16]; /* data_bias */

    /* separable_conv2d_3_39 */
    node[14]->input.tensors[0] = node[13]->output.tensors[0];
    node[14]->input.tensors[1] = const_tensor[17]; /* data_weight */
    node[14]->input.tensors[2] = const_tensor[18]; /* data_bias */

    /* p_re_lu_3_36 */
    node[15]->input.tensors[0] = node[14]->output.tensors[0];
    node[15]->input.tensors[1] = const_tensor[19]; /* data_a */

    /* max_pooling2d_3_35 */
    node[16]->input.tensors[0] = node[15]->output.tensors[0];

    /* separable_conv2d_4_33 */
    node[17]->input.tensors[0] = node[16]->output.tensors[0];
    node[17]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[17]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* separable_conv2d_4_34 */
    node[18]->input.tensors[0] = node[17]->output.tensors[0];
    node[18]->input.tensors[1] = const_tensor[22]; /* data_weight */
    node[18]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* p_re_lu_4_31 */
    node[19]->input.tensors[0] = node[18]->output.tensors[0];
    node[19]->input.tensors[1] = const_tensor[24]; /* data_a */

    /* max_pooling2d_4_30 */
    node[20]->input.tensors[0] = node[19]->output.tensors[0];

    /* separable_conv2d_5_28 */
    node[21]->input.tensors[0] = node[20]->output.tensors[0];
    node[21]->input.tensors[1] = const_tensor[25]; /* data_weight */
    node[21]->input.tensors[2] = const_tensor[26]; /* data_bias */

    /* separable_conv2d_5_29 */
    node[22]->input.tensors[0] = node[21]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[27]; /* data_weight */
    node[22]->input.tensors[2] = const_tensor[28]; /* data_bias */

    /* p_re_lu_5_26 */
    node[23]->input.tensors[0] = node[22]->output.tensors[0];
    node[23]->input.tensors[1] = const_tensor[29]; /* data_a */

    /* max_pooling2d_5_25 */
    node[24]->input.tensors[0] = node[23]->output.tensors[0];

    /* flatten_24_acuity_mark_perm_6 */
    node[25]->input.tensors[0] = node[24]->output.tensors[0];

    /* flatten_24 */
    node[26]->input.tensors[0] = node[25]->output.tensors[0];

    /* dense_3_22 */
    node[27]->input.tensors[0] = node[26]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[30]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* dense_23 */
    node[28]->input.tensors[0] = node[26]->output.tensors[0];
    node[28]->input.tensors[1] = const_tensor[32]; /* data_weight */
    node[28]->input.tensors[2] = const_tensor[33]; /* data_bias */

    /* p_re_lu_9_20 */
    node[29]->input.tensors[0] = node[27]->output.tensors[0];
    node[29]->input.tensors[1] = const_tensor[34]; /* data_a */

    /* p_re_lu_6_21 */
    node[30]->input.tensors[0] = node[28]->output.tensors[0];
    node[30]->input.tensors[1] = const_tensor[35]; /* data_a */

    /* dense_4_16 */
    node[31]->input.tensors[0] = node[29]->output.tensors[0];
    node[31]->input.tensors[1] = const_tensor[36]; /* data_weight */
    node[31]->input.tensors[2] = const_tensor[37]; /* data_bias */

    /* dense_1_17 */
    node[32]->input.tensors[0] = node[30]->output.tensors[0];
    node[32]->input.tensors[1] = const_tensor[38]; /* data_weight */
    node[32]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* p_re_lu_10_14 */
    node[33]->input.tensors[0] = node[31]->output.tensors[0];
    node[33]->input.tensors[1] = const_tensor[40]; /* data_a */

    /* p_re_lu_7_15 */
    node[34]->input.tensors[0] = node[32]->output.tensors[0];
    node[34]->input.tensors[1] = const_tensor[41]; /* data_a */

    /* dense_5_10 */
    node[35]->input.tensors[0] = node[33]->output.tensors[0];
    node[35]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[35]->input.tensors[2] = const_tensor[43]; /* data_bias */

    /* dense_2_11 */
    node[36]->input.tensors[0] = node[34]->output.tensors[0];
    node[36]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[36]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* p_re_lu_11_8 */
    node[37]->input.tensors[0] = node[35]->output.tensors[0];
    node[37]->input.tensors[1] = const_tensor[46]; /* data_a */

    /* p_re_lu_8_9 */
    node[38]->input.tensors[0] = node[36]->output.tensors[0];
    node[38]->input.tensors[1] = const_tensor[47]; /* data_a */

    /* output_upper_bound_2 */
    node[39]->input.tensors[0] = node[37]->output.tensors[0];
    node[39]->input.tensors[1] = const_tensor[48]; /* data_weight */
    node[39]->input.tensors[2] = const_tensor[49]; /* data_bias */

    /* output_lower_bound_4 */
    node[40]->input.tensors[0] = node[38]->output.tensors[0];
    node[40]->input.tensors[1] = const_tensor[50]; /* data_weight */
    node[40]->input.tensors[2] = const_tensor[51]; /* data_bias */

    /* output_upper_bound_relu_3 */
    node[41]->input.tensors[0] = node[39]->output.tensors[0];

    /* output_lower_bound_relu_5 */
    node[42]->input.tensors[0] = node[40]->output.tensors[0];


    graph->output.tensors[0] = norm_tensor[0];
    graph->output.tensors[1] = norm_tensor[1];
    graph->input.tensors[0] = norm_tensor[2];


    if( enable_pre_post_process )
    {
        sort = TRUE;
        if( pre_process_map_count > 0 )
        {
            for( i = 0; i < pre_process_map_count; i++ )
            {
                status = vsi_nn_AddGraphPreProcess(graph, pre_process_map[i].graph_input_idx,
                                                   pre_process_map[i].preprocesses,
                                                   pre_process_map[i].preprocess_count);
                TEST_CHECK_STATUS( status, error );
            }
        }

        if( post_process_map_count > 0 )
        {
            for( i = 0; i < post_process_map_count; i++ )
            {
                 status = vsi_nn_AddGraphPostProcess(graph, post_process_map[i].graph_output_idx,
                                                     post_process_map[i].postprocesses,
                                                     post_process_map[i].postprocess_count);
                 TEST_CHECK_STATUS( status, error );
            }
        }
    }

    status = vsi_nn_SetupGraph( graph, sort );
    TEST_CHECK_STATUS( status, error );
    vsi_nn_DumpGraphToJson( graph );

    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vsi_nn_DumpGraphToJson( graph );
    vnn_ReleaseGenderh5( graph, release_ctx );

    return NULL;
} /* vsi_nn_CreateGenderh5() */

void vnn_ReleaseGenderh5
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vsi_nn_ReleaseGenderh5() */

